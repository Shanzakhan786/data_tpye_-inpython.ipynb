{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d9a00a",
   "metadata": {},
   "source": [
    "# **AWFERA : Python Course**\n",
    "\n",
    "# **Lecture No : 19** (Part 1)\n",
    "\n",
    "# **Topic : AI APIs And OpenAI APIs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b5bf86",
   "metadata": {},
   "source": [
    "# **Introduction to AI APIs :**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438f92bc",
   "metadata": {},
   "source": [
    "#### **What are AI APIs ? & Why Learn them?**\n",
    "\n",
    "AI APIs **(Application Pragrammin Interface)** that especial services that let your python program access powerful Ai\n",
    "\n",
    "capabilites without building AI models yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93d0958",
   "metadata": {},
   "source": [
    "#### **Think of AI APIs Like having a conversation:** \n",
    "\n",
    "Think Of AI APIs like having converstion with a very smart computer that can generate text, images, and even videos. You can ask it questions, \n",
    "\n",
    "provide it with data, and it will respond with the output you need. Just like how you would have a conversation with a human."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64253546",
   "metadata": {},
   "source": [
    "#### **How APIs Work:**\n",
    "\n",
    "APIs Work by sending a requrest with your input text or question and the API returns an AI_generated result back\n",
    "\n",
    "to your program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ffa340",
   "metadata": {},
   "source": [
    "#### **Popular AI APIs :**\n",
    "\n",
    "Popular AI APIs include **OpenAI** and **Google AI Studio**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffe6a0",
   "metadata": {},
   "source": [
    "# **What Are AI APIs ?**\n",
    "\n",
    "\n",
    "\n",
    "**AI APIs (Artificial Intelligence Application Programming Interfaces)** are tools that allow developers to easily add AI features to their apps or websites without building complex models from scratch.\n",
    "\n",
    "## Key Features:\n",
    "- Pre-trained models for tasks like:\n",
    "  - Text generation\n",
    "  - Image recognition\n",
    "  - Speech-to-text\n",
    "  - Language translation\n",
    "- Easy integration using REST APIs or SDKs\n",
    "- Return results in formats like JSON\n",
    "\n",
    "## Examples:\n",
    "- **OpenAI API** â€“ for chatbots, text generation\n",
    "- **Google Cloud Vision API** â€“ for analyzing images\n",
    "- **IBM Watson API** â€“ for natural language understanding\n",
    "\n",
    "## Why Use AI APIs?\n",
    "- Saves time and effort\n",
    "- No need for deep AI knowledge\n",
    "- Scalable and reliable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7ad8e8",
   "metadata": {},
   "source": [
    " # **Why Use API Keys?**\n",
    "\n",
    "**API keys** are unique codes used to identify and authenticate a user or application accessing an API.\n",
    "\n",
    "## Reasons to Use API Keys:\n",
    "\n",
    "- âœ… **Authentication**  \n",
    "  Helps verify who is making the API request.\n",
    "\n",
    "- ðŸ” **Security**  \n",
    "  Prevents unauthorized access to the API.\n",
    "\n",
    "- ðŸ“Š **Usage Tracking**  \n",
    "  Tracks how often the API is used and by whom.\n",
    "\n",
    "- ðŸ“‹ **Access Control**  \n",
    "  Limits what users or apps can do with the API (like request limits or feature access).\n",
    "\n",
    "- ðŸ’° **Billing**  \n",
    "  Used for charging based on usage if the API is paid.\n",
    "\n",
    "> API keys are like passwords that apps use to safely talk to each other.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e29f7",
   "metadata": {},
   "source": [
    " # **API key Security and Best Practices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9438e0b1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Security Concerns:\n",
    "- **Exposure Risk:** If someone gets your API key, they can misuse your API access.\n",
    "- **No Encryption:** API keys are often sent in plain text, so using HTTPS is important.\n",
    "- **Limited Scope:** API keys alone donâ€™t provide user-level access control.\n",
    "\n",
    "## Best Practices:\n",
    "- ðŸ”’ **Keep Keys Secret**  \n",
    "  Never share API keys publicly (e.g., in public repos or client-side code).\n",
    "\n",
    "- ðŸ”„ **Rotate Keys Regularly**  \n",
    "  Change your keys periodically to reduce risk if compromised.\n",
    "\n",
    "- ðŸŽ¯ **Use Scoped Keys**  \n",
    "  Restrict keys to only necessary permissions or APIs.\n",
    "\n",
    "- ðŸŒ **Use HTTPS**  \n",
    "  Always use secure connections to protect keys in transit.\n",
    "\n",
    "- ðŸ›‘ **Set Usage Limits**  \n",
    "  Apply rate limits and quotas to prevent abuse.\n",
    "\n",
    "- ðŸ§¾ **Monitor Usage**  \n",
    "  Track API key activity to detect suspicious behavior.\n",
    "\n",
    "- ðŸ› ï¸ **Revoke Compromised Keys**  \n",
    "  Immediately disable any keys suspected to be leaked or misused.\n",
    "\n",
    "  **## What are Environment Files?** \n",
    "  \n",
    "Environment files (like `.env`) store secret information such as API keys, database URLs, and tokens outside the main code.\n",
    "\n",
    "> Following these best practices helps protect your API keys and keeps your applications safe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e815ab",
   "metadata": {},
   "source": [
    "# **In Python (using dotenv):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddd1bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735db91",
   "metadata": {},
   "source": [
    "**Best Practices:**\n",
    "\n",
    "âœ… Add .env to .gitignore\n",
    "\n",
    "âœ… Keep .env files private\n",
    "\n",
    "âœ… Use different files for development and production\n",
    "\n",
    "Environment files help keep your secrets safe and your code organized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7c3a9",
   "metadata": {},
   "source": [
    "# **How to Get API Keys from OpenAI And Google AI studio** :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84b1b1",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "Follow these steps to get your OpenAI API key:\n",
    "\n",
    "## ðŸ”— Step 1: Go to OpenAI's Platform \n",
    "Visit: [https://platform.openai.com](https://platform.openai.com)\n",
    "\n",
    "https://aistudio.google.com/prompts/new_chat\n",
    "\n",
    "## ðŸ§‘â€ðŸ’¼ Step 2: Sign In or Sign Up\n",
    "- Log in with your OpenAI account.\n",
    "- If you don't have one, create a free account.\n",
    "\n",
    "## ðŸ”‘ Step 3: Go to API Keys Section\n",
    "- Click your profile icon (top-right).\n",
    "- Select **\"API Keys\"** from the dropdown.\n",
    "\n",
    "## âž• Step 4: Create a New Key\n",
    "- Click **\"Create new secret key\"**.\n",
    "- Copy and save it securely (you wonâ€™t see it again!).\n",
    "\n",
    "## ðŸ“‹ Step 5: Use Your Key in Code\n",
    "Example in Python:\n",
    "```python\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"your_api_key_here\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b795e23",
   "metadata": {},
   "source": [
    "# Creating and Using `.env` Files\n",
    "\n",
    "## ðŸ“„ What is a `.env` File?\n",
    "A `.env` file stores environment variables (like API keys, database URLs) in **key=value** format.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ› ï¸ Step 1: Create a `.env` File\n",
    "\n",
    "In your project root folder, create a file named `.env` and add:\n",
    "```env\n",
    "OPEN_API_KEY= \"your_secret_api_key\"\n",
    "GOOGLE_API_KEY= \"your_secret_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e157059e",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 2: Install python-dotenv (for Python projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57706bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eadf9c",
   "metadata": {},
   "source": [
    "## ðŸ Step 3: Load .env in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c94b000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPEN_API_KEY loaded successfully,\n",
      "GOOGLE_API_KEY loaded successfully,\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # loads variables from .env\n",
    "\n",
    "#Function to get an API key by name\n",
    "def get_api_key(key_name):\n",
    "    try:\n",
    "        key = os.getenv(key_name)\n",
    "        if key :\n",
    "            print(f\"{key_name} loaded successfully,\")\n",
    "        else:\n",
    "            print(f\"{key_name} not found .please ckeck your .env file.\")\n",
    "        return key\n",
    "    except Exception as error:\n",
    "        print(f\"Something went wrong while loading {key_name}: {error}\")\n",
    "        return None    \n",
    "    \n",
    "#Load API Keys \n",
    "open_api_key = get_api_key(\"OPEN_API_KEY\")\n",
    "google_api_key = get_api_key(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d20c337",
   "metadata": {},
   "source": [
    "# Alternative Method: Using Environment Variables Directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846a19a",
   "metadata": {},
   "source": [
    "if you can\"t use .env file exampke in some online envirmoment , you can use enviroment directly in your code,\n",
    "\n",
    "but this is less secure:\n",
    "\n",
    "**set API_KEY=\"your_secret_api_key\"**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80e7b1",
   "metadata": {},
   "source": [
    "# **Using The OpenAI API:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee12d89",
   "metadata": {},
   "source": [
    "# What is OpenAI?\n",
    "\n",
    "**OpenAI** is a research and development company focused on creating and promoting artificial intelligence (AI) that benefits humanity.\n",
    "\n",
    "## ðŸŒŸ Key Points:\n",
    "\n",
    "- Founded in **2015** by Elon Musk, Sam Altman, and others.\n",
    "- Known for creating advanced AI models like:\n",
    "  - **ChatGPT** â€“ for conversational AI\n",
    "  - **GPT-4** â€“ for text understanding and generation\n",
    "  - **DALLÂ·E** â€“ for image generation from text\n",
    "  - **Codex** â€“ for code generation and assistance\n",
    "\n",
    "## ðŸŽ¯ Goal:\n",
    "To ensure that **artificial general intelligence (AGI)** is safe and aligned with human values.\n",
    "\n",
    "## ðŸ”§ Offers:\n",
    "- APIs for developers\n",
    "- Tools for writing, coding, chatting, and creating\n",
    "\n",
    "> OpenAI makes powerful AI tools that help people solve problems, create content, and build smart apps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90d5889",
   "metadata": {},
   "source": [
    "## Step 1 : Install the OpenAi Python Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aa8d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.82.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Downloading pydantic-2.11.5-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\anaconda3\\envs\\awfera\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "   ---------------------------------------- 0.0/720.4 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 524.3/720.4 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 720.4/720.4 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.10.0-cp310-cp310-win_amd64.whl (207 kB)\n",
      "Downloading pydantic-2.11.5-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/2.0 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 2.6 MB/s eta 0:00:00\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-inspection, tqdm, sniffio, pydantic-core, jiter, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.10.0 openai-1.82.0 pydantic-2.11.5 pydantic-core-2.33.2 sniffio-1.3.1 tqdm-4.67.1 typing-inspection-0.4.1\n"
     ]
    }
   ],
   "source": [
    "# Install the OpenAi package\n",
    "!undefinedpip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311a82c1",
   "metadata": {},
   "source": [
    "## Step 2 : Set Up the OpenAI Client : \n",
    "\n",
    "Now we'll create an OpenAI client using our API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c4a7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI client created successfully!\n"
     ]
    }
   ],
   "source": [
    "#Import the OpenAI client\n",
    "from openai import OpenAI\n",
    "\n",
    "# Create  a client instance using our API key\n",
    "client = OpenAI(api_key = open_api_key)\n",
    "\n",
    "# If the API key is loaded correctly , this print a successfully\n",
    "if client :\n",
    "    print(\"OpenAI client created successfully!\")\n",
    "else:\n",
    "    print(\"Failed to create OpenAI client.Check your API key\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26003c7d",
   "metadata": {},
   "source": [
    "## Step 3 : Make a Simple text Completion Request with GPT-4.1-mini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dc8e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_api_respone(prompt):\n",
    "    \"\"\"Function to get respone from OpenAI GPT-4.1 model.\n",
    "    Args:\n",
    "        prompt (str): The text to send to the Ai\n",
    "        \n",
    "    Returns:\n",
    "        str: The AI 's respone\n",
    "    \"\"\"\n",
    "try:\n",
    "    \n",
    "# Make a request to GPT-4.1-mini\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Write a short story about a robot who wants to become a painter.\"}\n",
    "    ],\n",
    "    max_tokens=100,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81f7598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def get_api_response(prompt):\n",
    "    \"\"\"\n",
    "    Function to get response from OpenAI GPT-4.1-mini model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The text prompt to send to the AI.\n",
    "\n",
    "    Returns:\n",
    "        str: The AI's response.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4.1-mini\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    prompt_text = \"Write a short story about a robot who wants to become a painter.\"\n",
    "    result = get_api_response(prompt_text)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c05f8",
   "metadata": {},
   "source": [
    "## ðŸ“ Explanation Summary:\n",
    "\n",
    "dotenv: Loads API keys securely from .env file.\n",
    "\n",
    "openai.ChatCompletion.create: Calls the GPT model using Chat API.\n",
    "\n",
    "temperature: Adjusts creativity (0.7 = moderately creative).\n",
    "\n",
    "max_tokens: Controls length of the response.\n",
    "\n",
    "Try/Except: Prevents crashes by catching errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e282f8",
   "metadata": {},
   "source": [
    "## ðŸ¤ Step 4: Create a Multi-Turn Conversation with GPT-4.0-mini\n",
    "\n",
    "This step shows how to simulate an ongoing chat by maintaining context between the user and the assistant.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  What is a Multi-Turn Conversation?\n",
    "\n",
    "A multi-turn conversation keeps track of earlier messages so that the AI responds more contextually. You send a **list of messages**, each with a `role` (`system`, `user`, or `assistant`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dabb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### ðŸ§ª Sample Python Code:\n",
    "\n",
    "```python\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ðŸ” Load API key from .env\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def multi_turn_chat():\n",
    "    \"\"\"\n",
    "    Simulates a multi-turn conversation using GPT-4.0-mini.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, who won the cricket World Cup in 2019?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"England won the 2019 Cricket World Cup.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Who was the captain of that team?\"}\n",
    "        ]\n",
    "\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4.0-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "\n",
    "        print(\"ðŸ¤– GPT Response:\", response.choices[0].message.content)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âš ï¸ Error:\", e)\n",
    "\n",
    "# ðŸš€ Run the multi-turn chat\n",
    "if __name__ == \"__main__\":\n",
    "    multi_turn_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad92fe",
   "metadata": {},
   "source": [
    "#### **ðŸ§¾ Explanation:**\n",
    "\n",
    "system: Sets the assistant's behavior.\n",
    "\n",
    "user and assistant: Mimic a real conversation.\n",
    "\n",
    "Context is preserved by passing previous turns in messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f75b371",
   "metadata": {},
   "source": [
    "## â— Step 5: Error Handling for OpenAI API in Python\n",
    "\n",
    "When using the OpenAI API, it's important to handle potential errors like rate limits, network issues, or invalid inputs.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§ª Sample Python Code with Error Handling\n",
    "\n",
    "```python\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load API key\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def safe_chat(prompt):\n",
    "    \"\"\"\n",
    "    Sends a prompt to OpenAI and handles common errors gracefully.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4.0-mini\",\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    except openai.error.AuthenticationError:\n",
    "        return \"âŒ Invalid API key. Please check your .env file.\"\n",
    "\n",
    "    except openai.error.RateLimitError:\n",
    "        return \"ðŸš« Rate limit exceeded. Try again later.\"\n",
    "\n",
    "    except openai.error.APIConnectionError:\n",
    "        return \"ðŸŒ Network error. Please check your internet connection.\"\n",
    "\n",
    "    except openai.error.InvalidRequestError as e:\n",
    "        return f\"âš ï¸ Invalid request: {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"â— Unexpected error: {e}\"\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    user_prompt = \"Tell me a joke about computers.\"\n",
    "    print(safe_chat(user_prompt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353a483",
   "metadata": {},
   "source": [
    "# âŒ Common OpenAI API Errors and Solutions\n",
    "\n",
    "Below are frequently encountered errors when using the OpenAI API, along with descriptions and how to handle them.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. ðŸ” `AuthenticationError`\n",
    "**Message**: `Invalid API key provided.`  \n",
    "**Cause**: API key is missing, invalid, or incorrectly set.  \n",
    "**Solution**:  \n",
    "- Make sure `.env` file contains: `OPENAI_API_KEY=your-key-here`\n",
    "- Load with `load_dotenv()` and `os.getenv(\"OPENAI_API_KEY\")`\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ðŸš« `RateLimitError`\n",
    "**Message**: `You exceeded your current quota, please check your plan and billing details.`  \n",
    "**Cause**: Too many requests in a short time or free quota exhausted.  \n",
    "**Solution**:  \n",
    "- Reduce request frequency  \n",
    "- Upgrade your OpenAI plan if needed  \n",
    "- Implement retry logic with delay\n",
    "\n",
    "---\n",
    "\n",
    "## 3. ðŸŒ `APIConnectionError`\n",
    "**Message**: `Error communicating with OpenAI servers.`  \n",
    "**Cause**: Network issues, DNS failure, or server downtime.  \n",
    "**Solution**:  \n",
    "- Check your internet connection  \n",
    "- Retry after a few seconds\n",
    "\n",
    "---\n",
    "\n",
    "## 4. âš ï¸ `InvalidRequestError`\n",
    "**Message**: `Unrecognized request argument`, `Too many tokens`, etc.  \n",
    "**Cause**: Request is malformed or exceeds model limits.  \n",
    "**Solution**:  \n",
    "- Check for typos in parameters  \n",
    "- Ensure token count â‰¤ model's token limit (e.g., 4096 tokens for many models)\n",
    "\n",
    "---\n",
    "\n",
    "## 5. âš™ï¸ `ServiceUnavailableError`\n",
    "**Message**: `The server is overloaded or down for maintenance.`  \n",
    "**Cause**: OpenAI server is temporarily unavailable.  \n",
    "**Solution**:  \n",
    "- Wait and retry after a few minutes  \n",
    "- Use exponential backoff\n",
    "\n",
    "---\n",
    "\n",
    "## 6. â— `OpenAIError`\n",
    "**Message**: Generic internal error  \n",
    "**Cause**: Unknown issue or uncategorized server problem.  \n",
    "**Solution**:  \n",
    "- Wrap in `try/except` and log the error  \n",
    "- Retry or contact OpenAI support if persistent\n",
    "\n",
    "---\n",
    "\n",
    "> âœ… Tip: Always use `try/except` blocks to handle these errors gracefully in production.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb60fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awfera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
